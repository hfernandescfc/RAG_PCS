import os
import sys
import glob
import hashlib
import json
import gc

# AVISO: Este script 'main.py' estÃ¡ obsoleto.
# Use os entrypoints dedicados:
# - IngestÃ£o: python src/rag_processar_corrigido.py
# - CLI:      python src/query_cli.py
# - Web App:  streamlit run src/rag_pipeline/app.py

# Verificar e configurar Tesseract
def verificar_tesseract():
    caminhos_possiveis = [
        r'C:\Program Files\Tesseract-OCR\tesseract.exe',
        r'C:\Program Files (x86)\Tesseract-OCR\tesseract.exe',
        r'C:\Tesseract-OCR\tesseract.exe',
    ]
    for caminho in caminhos_possiveis:
        if os.path.exists(caminho):
            return caminho
    return None

def calcular_hash_arquivo(filepath):
    """Calcula hash MD5 de um arquivo"""
    hash_md5 = hashlib.md5()
    with open(filepath, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def carregar_registro_processados(registro_path="./arquivos_processados.json"):
    """Carrega registro de arquivos jÃ¡ processados"""
    if os.path.exists(registro_path):
        with open(registro_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def salvar_registro_processados(registro, registro_path="./arquivos_processados.json"):
    """Salva registro de arquivos processados"""
    with open(registro_path, 'w', encoding='utf-8') as f:
        json.dump(registro, f, indent=2, ensure_ascii=False)

def verificar_pdf_tem_texto(pdf_path):
    """Verifica se PDF tem texto extraÃ­vel"""
    try:
        from PyPDF2 import PdfReader
        reader = PdfReader(pdf_path)
        
        for i, page in enumerate(reader.pages[:3]):
            text = page.extract_text().strip()
            if len(text) > 100:
                return True
        return False
    except:
        return False

def processar_pdf_com_texto(pdf_path, nome_arquivo):
    """Extrai texto direto do PDF"""
    from langchain_community.document_loaders import PyPDFLoader
    from langchain.docstore.document import Document
    
    print("   ğŸ“ ExtraÃ§Ã£o direta...")
    
    try:
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()
        
        documents = [doc for doc in documents if doc.page_content.strip()]
        
        if documents:
            for i, doc in enumerate(documents):
                doc.metadata['source'] = nome_arquivo
                doc.metadata['page'] = i + 1
                doc.metadata['file_path'] = pdf_path
                doc.metadata['metodo'] = 'extraÃ§Ã£o_direta'
            
            return documents, 'extraÃ§Ã£o_direta'
    except Exception as e:
        print(f"   âš ï¸  Erro: {e}")
    
    return None, None

def processar_pdf_com_ocr(pdf_path, nome_arquivo, pytesseract, convert_from_path):
    """Extrai texto com OCR - OTIMIZADO PARA MEMÃ“RIA"""
    from langchain.docstore.document import Document
    
    print("   ğŸ–¼ï¸  OCR (processando pÃ¡gina por pÃ¡gina)...")
    
    try:
        # Descobrir nÃºmero de pÃ¡ginas SEM carregar tudo
        from PyPDF2 import PdfReader
        reader = PdfReader(pdf_path)
        total_paginas = len(reader.pages)
        print(f"   Total: {total_paginas} pÃ¡ginas")
        
        documents = []
        
        # PROCESSAR PÃGINA POR PÃGINA (economia de memÃ³ria)
        for page_num in range(1, total_paginas + 1):
            try:
                percent = (page_num / total_paginas) * 100
                print(f"      [{page_num}/{total_paginas}] {percent:.0f}%", end="\r")
                
                # Converter apenas UMA pÃ¡gina por vez
                images = convert_from_path(
                    pdf_path,
                    dpi=200,  # Reduzido de 300 para economizar memÃ³ria
                    first_page=page_num,
                    last_page=page_num,
                    fmt='jpeg'
                )
                
                if images:
                    image = images[0]
                    
                    # OCR
                    text = pytesseract.image_to_string(
                        image,
                        lang='por',
                        config='--psm 3 --oem 1'
                    )
                    
                    if text.strip():
                        doc = Document(
                            page_content=text.strip(),
                            metadata={
                                "source": nome_arquivo,
                                "page": page_num,
                                "file_path": pdf_path,
                                "metodo": "ocr"
                            }
                        )
                        documents.append(doc)
                    
                    # LIBERAR MEMÃ“RIA
                    del images
                    del image
                    gc.collect()
                    
            except Exception as e:
                print(f"\n      âš ï¸  Erro pÃ¡gina {page_num}: {e}")
        
        print(f"\n   âœ… {len(documents)} pÃ¡ginas extraÃ­das")
        return documents, 'ocr'
        
    except Exception as e:
        print(f"   âŒ Erro no OCR: {e}")
        return None, None

def processar_e_salvar_arquivo(arq_info, registro, embeddings, db_path, ocr_disponivel, 
                               pytesseract=None, convert_from_path=None):
    """Processa UM arquivo e salva IMEDIATAMENTE no banco"""
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import Chroma
    from datetime import datetime
    
    pdf_path = arq_info['path']
    nome_arquivo = arq_info['nome']
    hash_arquivo = arq_info['hash']
    
    print(f"\n{'='*70}")
    print(f"ğŸ“„ {nome_arquivo}")
    print('='*70)
    
    # Tentar extraÃ§Ã£o direta primeiro
    print("1ï¸âƒ£  Verificando se tem texto extraÃ­vel...")
    tem_texto = verificar_pdf_tem_texto(pdf_path)
    
    documents = None
    metodo = None
    
    if tem_texto:
        print("   âœ… Tem texto!")
        documents, metodo = processar_pdf_com_texto(pdf_path, nome_arquivo)
    
    # Se falhou ou nÃ£o tem texto, tentar OCR
    if not documents and ocr_disponivel:
        print("2ï¸âƒ£  Usando OCR...")
        documents, metodo = processar_pdf_com_ocr(pdf_path, nome_arquivo, 
                                                  pytesseract, convert_from_path)
    
    if not documents:
        print("   âŒ Falhou ao processar")
        return False
    
    # Dividir em chunks
    print("   âœ‚ï¸  Criando chunks...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )
    docs = text_splitter.split_documents(documents)
    docs = [doc for doc in docs if doc.page_content.strip()]
    print(f"   âœ… {len(docs)} chunks")
    
    # SALVAR NO BANCO IMEDIATAMENTE
    print("   ğŸ’¾ Salvando no banco...")
    
    try:
        if os.path.exists(db_path):
            # Adicionar ao banco existente
            db = Chroma(persist_directory=db_path, embedding_function=embeddings)
            db.add_documents(docs)
        else:
            # Criar novo banco
            db = Chroma.from_documents(docs, embeddings, persist_directory=db_path)
        
        print("   âœ… Salvo!")
        
        # REGISTRAR SUCESSO
        registro[hash_arquivo] = {
            'nome': nome_arquivo,
            'caminho': pdf_path,
            'metodo': metodo,
            'paginas': len(documents),
            'chunks': len(docs),
            'data_processo': datetime.now().isoformat()
        }
        salvar_registro_processados(registro)
        
        # LIBERAR MEMÃ“RIA
        del documents
        del docs
        del db
        gc.collect()
        
        return True
        
    except Exception as e:
        print(f"   âŒ Erro ao salvar: {e}")
        return False

print("ğŸ”§ Sistema RAG Otimizado para Baixa MemÃ³ria (8GB)\n")

# Verificar Tesseract
tesseract_path = verificar_tesseract()

if not tesseract_path:
    print("âš ï¸  Tesseract nÃ£o encontrado - OCR desabilitado")
    ocr_disponivel = False
else:
    print(f"âœ… Tesseract: {tesseract_path}")
    ocr_disponivel = True

# Importar bibliotecas
try:
    from langchain_community.document_loaders import PyPDFLoader
    from PyPDF2 import PdfReader
    import requests
    from langchain_community.vectorstores import Chroma
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_community.llms import Ollama
    from langchain.chains import RetrievalQA
except ImportError as e:
    print(f"âŒ Erro: {e}")
    print("Instale: pip install langchain-community PyPDF2 requests")
    sys.exit(1)

if ocr_disponivel:
    try:
        from pdf2image import convert_from_path
        import pytesseract
        pytesseract.pytesseract.tesseract_cmd = tesseract_path
    except ImportError:
        print("âš ï¸  pdf2image/pytesseract nÃ£o disponÃ­veis")
        ocr_disponivel = False
        pytesseract = None
        convert_from_path = None

print()

# ============================================================================
# CONFIGURAÃ‡ÃƒO: Adicione seus PDFs aqui
# ============================================================================

pdf_folder = r"C:\Users\compesa\Desktop\ppp_RAG"

# A busca agora Ã© recursiva para encontrar arquivos .pdf e .PDF em todas as subpastas
# O '**' indica que a busca deve incluir todos os subdiretÃ³rios
pdf_files = glob.glob(os.path.join(pdf_folder, "**", "*.pdf"), recursive=True)
pdf_files += glob.glob(os.path.join(pdf_folder, "**", "*.PDF"), recursive=True)
# ============================================================================

pdf_files = [f for f in pdf_files if os.path.exists(f)]

if not pdf_files:
    print("âŒ Nenhum PDF encontrado!")
    sys.exit(1)

# Carregar registro
registro = carregar_registro_processados()
print(f"ğŸ“‹ Arquivos jÃ¡ processados: {len(registro)}\n")

# Verificar o que processar
arquivos_para_processar = []
hashes_vistos = set()

print("ğŸ” Verificando arquivos...\n")

for pdf_path in pdf_files:
    nome_arquivo = os.path.basename(pdf_path)
    hash_arquivo = calcular_hash_arquivo(pdf_path)
    
    if hash_arquivo in registro:
        info = registro[hash_arquivo]
        print(f"â­ï¸  {nome_arquivo} (jÃ¡ processado em {info.get('metodo', '?')})")
        continue
    
    if hash_arquivo in hashes_vistos:
        print(f"âš ï¸  {nome_arquivo} (duplicado)")
        continue
    
    hashes_vistos.add(hash_arquivo)
    size_mb = os.path.getsize(pdf_path) / (1024*1024)
    print(f"âœ… {nome_arquivo} ({size_mb:.2f} MB)")
    
    arquivos_para_processar.append({
        'path': pdf_path,
        'nome': nome_arquivo,
        'hash': hash_arquivo
    })

print(f"\n{'='*70}")
print(f"ğŸ“Š Para processar: {len(arquivos_para_processar)} arquivos")
print('='*70)

if not arquivos_para_processar:
    print("\nâœ… Todos jÃ¡ processados! Carregando banco...\n")
else:
    # Criar embeddings UMA VEZ
    print("\nğŸ§  Inicializando embeddings...")
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True, 'batch_size': 8}  # Batch menor
    )
    print("âœ… Embeddings prontos")
    
    db_path = "./chroma_db_multiplos"
    
    # PROCESSAR ARQUIVO POR ARQUIVO
    sucesso = 0
    falhas = 0
    
    for i, arq_info in enumerate(arquivos_para_processar, 1):
        print(f"\n[{i}/{len(arquivos_para_processar)}]")
        
        try:
            if processar_e_salvar_arquivo(
                arq_info, registro, embeddings, db_path, 
                ocr_disponivel, pytesseract, convert_from_path
            ):
                sucesso += 1
            else:
                falhas += 1
        except Exception as e:
            print(f"   âŒ ERRO CRÃTICO: {e}")
            falhas += 1
        
        # ForÃ§ar limpeza de memÃ³ria
        gc.collect()
    
    print(f"\n{'='*70}")
    print(f"âœ… PROCESSAMENTO FINALIZADO")
    print('='*70)
    print(f"âœ… Sucesso: {sucesso} arquivos")
    print(f"âŒ Falhas: {falhas} arquivos")

# Carregar banco para consultas
print("\nğŸ’¾ Carregando banco vetorial...")

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

db = Chroma(persist_directory="./chroma_db_multiplos", embedding_function=embeddings)
print("âœ… Banco carregado")

# Verificar Ollama
print("\nğŸ¤– Verificando Ollama...")
try:
    response = requests.get("http://localhost:11434/api/tags", timeout=2)
    if response.status_code != 200:
        raise Exception()
    models = [m['name'] for m in response.json().get('models', [])]
    print(f"âœ… Ollama OK! Modelos: {models}")
except:
    print("âŒ Ollama nÃ£o estÃ¡ rodando!")
    print("Execute: ollama serve")
    sys.exit(1)

llm = Ollama(model="llama3.2:3b", temperature=0, num_ctx=2048)

retriever = db.as_retriever(search_kwargs={"k": 4})
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

print("\n" + "="*70)
print("âœ… SISTEMA PRONTO!")
print("="*70)
print(f"\nğŸ“š Base: {len(registro)} arquivos processados")

# Interface
while True:
    print("\nâ“ Pergunta (ou 'sair'):")
    query = input(">>> ").strip()
    
    if query.lower() in ['sair', 'exit', 'quit', '']:
        break
    
    print("\nğŸ” Buscando...\n")
    
    try:
        result = qa.invoke({"query": query})
        
        print("ğŸ“ Resposta:")
        print("-" * 70)
        print(result['result'])
        print("-" * 70)
        
        print("\nğŸ“š Fontes:")
        for i, doc in enumerate(result['source_documents'], 1):
            source = doc.metadata.get('source', '?')
            page = doc.metadata.get('page', '?')
            metodo = doc.metadata.get('metodo', '?')
            print(f"   [{i}] {source} (pÃ¡g. {page}) [{metodo}]")
            
    except Exception as e:
        print(f"âŒ Erro: {e}")

print("\nâœ… Encerrado!")
