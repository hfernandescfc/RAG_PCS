import os
import sys
import requests
from typing import List
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.docstore.document import Document
from rank_bm25 import BM25Okapi
import numpy as np

print("ğŸ”§ Sistema RAG com Busca HÃ­brida AvanÃ§ada\n")

# Verificar banco
db_path = "./chroma_db_multiplos"
if not os.path.exists(db_path):
    print("âŒ Banco nÃ£o encontrado!")
    sys.exit(1)

# Carregar embeddings
print("ğŸ’¾ Carregando sistema...")
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

db = Chroma(persist_directory=db_path, embedding_function=embeddings)
print("âœ… Banco carregado")

# Verificar Ollama
print("ğŸ¤– Verificando Ollama...")
try:
    response = requests.get("http://localhost:11434/api/tags", timeout=2)
    if response.status_code != 200:
        raise Exception()
    print("âœ… Ollama OK\n")
except:
    print("âŒ Ollama nÃ£o estÃ¡ rodando!")
    sys.exit(1)

llm = Ollama(model="llama3.2:3b", temperature=0, num_ctx=4096, num_predict=1024)

# ============================================================================
# BUSCA HÃBRIDA: Vetorial + BM25
# ============================================================================

class HybridRetriever:
    """Combina busca vetorial (semÃ¢ntica) com BM25 (palavra-chave)"""
    
    def __init__(self, vectorstore, weight_vector=0.5, weight_bm25=0.5):
        self.vectorstore = vectorstore
        self.weight_vector = weight_vector
        self.weight_bm25 = weight_bm25
        
        # Carregar todos os documentos para BM25
        print("ğŸ“š Indexando documentos para busca por palavra-chave...")
        all_data = vectorstore.get()
        
        self.all_docs = []
        for doc_id, text, metadata in zip(
            all_data['ids'],
            all_data['documents'],
            all_data['metadatas']
        ):
            self.all_docs.append(Document(
                page_content=text,
                metadata=metadata
            ))
        
        # Criar Ã­ndice BM25
        tokenized_docs = [doc.page_content.lower().split() for doc in self.all_docs]
        self.bm25 = BM25Okapi(tokenized_docs)
        
        print(f"âœ… {len(self.all_docs)} documentos indexados")
    
    def search(self, query: str, k: int = 6, filter_source: str = None) -> List[Document]:
        """
        Busca hÃ­brida com filtro opcional por documento
        
        Args:
            query: Pergunta do usuÃ¡rio
            k: NÃºmero de documentos a retornar
            filter_source: Nome do arquivo para filtrar (ex: "contrato.pdf")
        """
        
        # 1. BUSCA VETORIAL (semÃ¢ntica)
        if filter_source:
            # Filtrar por documento especÃ­fico
            vector_results = self.vectorstore.similarity_search(
                query,
                k=k*2,
                filter={"source": filter_source}
            )
        else:
            vector_results = self.vectorstore.similarity_search(query, k=k*2)
        
        # 2. BUSCA BM25 (palavra-chave)
        query_tokens = query.lower().split()
        bm25_scores = self.bm25.get_scores(query_tokens)
        
        # Pegar top k*2 documentos do BM25
        top_bm25_indices = np.argsort(bm25_scores)[::-1][:k*2]
        bm25_results = [self.all_docs[i] for i in top_bm25_indices]
        
        # Filtrar BM25 por documento se necessÃ¡rio
        if filter_source:
            bm25_results = [
                doc for doc in bm25_results 
                if doc.metadata.get('source') == filter_source
            ]
        
        # 3. COMBINAR E RE-RANQUEAR
        # Criar dicionÃ¡rio de scores
        doc_scores = {}
        
        # Scores vetoriais (normalizar de 0 a 1)
        for i, doc in enumerate(vector_results):
            doc_key = (doc.page_content, doc.metadata.get('source'), doc.metadata.get('page'))
            vector_score = 1.0 - (i / len(vector_results))  # Score decrescente
            doc_scores[doc_key] = {
                'doc': doc,
                'vector': vector_score * self.weight_vector,
                'bm25': 0
            }
        
        # Scores BM25 (normalizar de 0 a 1)
        max_bm25 = max(bm25_scores) if max(bm25_scores) > 0 else 1
        for i, doc in enumerate(bm25_results):
            doc_key = (doc.page_content, doc.metadata.get('source'), doc.metadata.get('page'))
            bm25_score = bm25_scores[top_bm25_indices[i]] / max_bm25
            
            if doc_key in doc_scores:
                doc_scores[doc_key]['bm25'] = bm25_score * self.weight_bm25
            else:
                doc_scores[doc_key] = {
                    'doc': doc,
                    'vector': 0,
                    'bm25': bm25_score * self.weight_bm25
                }
        
        # Calcular score final e ordenar
        scored_docs = []
        for doc_key, scores in doc_scores.items():
            final_score = scores['vector'] + scores['bm25']
            scored_docs.append({
                'doc': scores['doc'],
                'score': final_score,
                'vector_score': scores['vector'],
                'bm25_score': scores['bm25']
            })
        
        # Ordenar por score final
        scored_docs.sort(key=lambda x: x['score'], reverse=True)
        
        # Retornar top k com informaÃ§Ãµes de debug
        return scored_docs[:k]

# Criar retriever hÃ­brido
print("\nğŸ” Criando sistema de busca hÃ­brida...")
hybrid_retriever = HybridRetriever(
    db,
    weight_vector=0.5,  # 50% busca semÃ¢ntica
    weight_bm25=0.5     # 50% busca por palavra-chave
)
print("âœ… Busca hÃ­brida configurada\n")

# ============================================================================
# LISTAR DOCUMENTOS DISPONÃVEIS
# ============================================================================

def listar_documentos():
    """Lista todos os documentos disponÃ­veis"""
    all_data = db.get()
    sources = set(meta.get('source', 'Desconhecido') for meta in all_data['metadatas'])
    return sorted(sources)

documentos_disponiveis = listar_documentos()

print("ğŸ“„ Documentos disponÃ­veis no sistema:")
for i, doc in enumerate(documentos_disponiveis, 1):
    print(f"   {i}. {doc}")

# ============================================================================
# PROMPT OTIMIZADO
# ============================================================================

template_prompt = """VocÃª Ã© um assistente especializado em anÃ¡lise de documentos contratuais e tÃ©cnicos.

Use EXCLUSIVAMENTE as informaÃ§Ãµes dos documentos fornecidos abaixo para responder Ã  pergunta.

REGRAS CRÃTICAS:
1. Se a informaÃ§Ã£o NÃƒO estiver nos documentos, responda: "NÃ£o encontrei essa informaÃ§Ã£o nos documentos fornecidos"
2. SEMPRE cite o documento e pÃ¡gina especÃ­ficos
3. NÃƒO invente ou deduza informaÃ§Ãµes
4. Se houver informaÃ§Ãµes conflitantes, mencione todas com suas fontes
5. Seja preciso, objetivo e profissional

DOCUMENTOS RELEVANTES:
{context}

PERGUNTA: {question}

RESPOSTA (citando documento e pÃ¡gina):"""

PROMPT = PromptTemplate(
    template=template_prompt,
    input_variables=["context", "question"]
)

# ============================================================================
# FUNÃ‡ÃƒO DE BUSCA AVANÃ‡ADA
# ============================================================================

def buscar_avancada(query: str, filtrar_por_documento: str = None, 
                   ajustar_pesos: bool = False):
    """
    Busca avanÃ§ada com opÃ§Ãµes de filtro e ajuste
    
    Args:
        query: Pergunta
        filtrar_por_documento: Nome do arquivo (ex: "contrato.pdf")
        ajustar_pesos: Se True, prioriza BM25 (palavra-chave)
    """
    
    print(f"\n{'='*70}")
    print(f"â“ PERGUNTA: {query}")
    if filtrar_por_documento:
        print(f"ğŸ¯ Filtro: {filtrar_por_documento}")
    print('='*70)
    
    # Ajustar pesos se solicitado
    if ajustar_pesos:
        hybrid_retriever.weight_vector = 0.3
        hybrid_retriever.weight_bm25 = 0.7
        print("âš–ï¸  Modo: Priorizando palavras-chave (70%)")
    else:
        hybrid_retriever.weight_vector = 0.5
        hybrid_retriever.weight_bm25 = 0.5
        print("âš–ï¸  Modo: Balanceado (50% semÃ¢ntica / 50% palavra-chave)")
    
    # Buscar documentos
    print("\nğŸ” Buscando documentos relevantes...\n")
    
    scored_docs = hybrid_retriever.search(
        query,
        k=6,
        filter_source=filtrar_por_documento
    )
    
    if not scored_docs:
        print("âŒ Nenhum documento encontrado!")
        return
    
    # Mostrar resultados com scores
    print(f"ğŸ“š Top {len(scored_docs)} documentos encontrados:")
    print("-"*70)
    
    for i, item in enumerate(scored_docs, 1):
        doc = item['doc']
        source = doc.metadata.get('source', '?')
        page = doc.metadata.get('page', '?')
        score_total = item['score']
        score_vector = item['vector_score']
        score_bm25 = item['bm25_score']
        
        print(f"\n[{i}] {source} - PÃ¡gina {page}")
        print(f"    Score Total: {score_total:.3f} (Vetorial: {score_vector:.3f} | BM25: {score_bm25:.3f})")
        
        preview = doc.page_content[:200].replace('\n', ' ').strip()
        print(f"    Preview: {preview}...")
    
    print("\n" + "-"*70)
    
    # ValidaÃ§Ã£o do usuÃ¡rio
    print("\nğŸ’­ Os documentos acima sÃ£o relevantes?")
    print("   [s] Sim, gerar resposta")
    print("   [n] NÃ£o, tentar com outro filtro")
    print("   [p] Priorizar palavras-chave")
    print("   [Enter] Continuar")
    
    resp = input(">>> ").strip().lower()
    
    if resp == 'n':
        print("\nğŸ’¡ Experimente:")
        print("   1. Adicionar filtro por documento")
        print("   2. Reformular pergunta com termos do documento")
        print("   3. Usar busca literal (comando 'buscar')")
        return
    
    if resp == 'p':
        print("\nğŸ”„ Repetindo busca priorizando palavras-chave...")
        return buscar_avancada(query, filtrar_por_documento, ajustar_pesos=True)
    
    # Gerar resposta
    print("\nğŸ¤– Gerando resposta (aguarde 10-30s)...\n")
    
    try:
        # Preparar contexto
        docs_for_llm = [item['doc'] for item in scored_docs]
        context = "\n\n".join([
            f"[Documento: {doc.metadata.get('source')} - PÃ¡gina {doc.metadata.get('page')}]\n{doc.page_content}"
            for doc in docs_for_llm
        ])
        
        # Gerar resposta
        prompt_text = PROMPT.format(context=context, question=query)
        resposta = llm.invoke(prompt_text)
        
        print("="*70)
        print("ğŸ“ RESPOSTA:")
        print("="*70)
        print(resposta)
        print("="*70)
        
        print("\nğŸ“š Fontes utilizadas (com scores):")
        for i, item in enumerate(scored_docs, 1):
            doc = item['doc']
            source = doc.metadata.get('source', '?')
            page = doc.metadata.get('page', '?')
            score = item['score']
            print(f"[{i}] {source} (pÃ¡g. {page}) - RelevÃ¢ncia: {score:.3f}")
        
    except Exception as e:
        print(f"âŒ Erro: {e}")

# ============================================================================
# INTERFACE INTERATIVA
# ============================================================================

print("\n" + "="*70)
print("ğŸ’¬ SISTEMA RAG COM BUSCA HÃBRIDA")
print("="*70)

print("\nğŸ¯ Comandos especiais:")
print("   â€¢ 'filtrar [num]' - Buscar apenas no documento [num]")
print("   â€¢ 'buscar [termo]' - Busca literal")
print("   â€¢ 'docs' - Listar documentos")
print("   â€¢ 'sair' - Encerrar")

filtro_ativo = None

while True:
    print("\n" + "="*70)
    
    if filtro_ativo:
        print(f"ğŸ¯ Filtro ativo: {filtro_ativo}")
    
    query = input("â“ Pergunta: ").strip()
    
    if not query:
        continue
    
    if query.lower() in ['sair', 'exit', 'quit']:
        break
    
    # Comando: Listar documentos
    if query.lower() == 'docs':
        print("\nğŸ“„ Documentos disponÃ­veis:")
        documentos_disponiveis = listar_documentos()
        for i, doc in enumerate(documentos_disponiveis, 1):
            print(f"   {i}. {doc}")
        continue
    
    # Comando: Ativar filtro
    if query.lower().startswith('filtrar '):
        try:
            num = int(query.split()[1])
            if 1 <= num <= len(documentos_disponiveis):
                filtro_ativo = documentos_disponiveis[num-1]
                print(f"âœ… Filtro ativado: {filtro_ativo}")
                print("   (Digite 'filtrar off' para desativar)")
            else:
                print("âŒ NÃºmero invÃ¡lido")
        except:
            if 'off' in query.lower():
                filtro_ativo = None
                print("âœ… Filtro desativado")
            else:
                print("âŒ Uso: filtrar [nÃºmero] ou filtrar off")
        continue
    
    # Comando: Busca literal
    if query.lower().startswith('buscar '):
        termo = query[7:].strip()
        print(f"\nğŸ” Buscando termo: '{termo}'")
        
        all_data = db.get()
        encontrados = []
        
        for text, metadata in zip(all_data['documents'], all_data['metadatas']):
            if termo.lower() in text.lower():
                if filtro_ativo:
                    if metadata.get('source') == filtro_ativo:
                        encontrados.append((text, metadata))
                else:
                    encontrados.append((text, metadata))
        
        if encontrados:
            print(f"âœ… Encontrado em {len(encontrados)} trechos")
            for i, (text, meta) in enumerate(encontrados[:10], 1):
                source = meta.get('source', '?')
                page = meta.get('page', '?')
                idx = text.lower().find(termo.lower())
                preview = text[max(0, idx-50):idx+150]
                print(f"\n[{i}] {source} (pÃ¡g. {page})")
                print(f"    ...{preview}...")
        else:
            print("âŒ Termo nÃ£o encontrado")
        continue
    
    # Busca normal
    buscar_avancada(query, filtrar_por_documento=filtro_ativo)

print("\nâœ… Encerrado!")
